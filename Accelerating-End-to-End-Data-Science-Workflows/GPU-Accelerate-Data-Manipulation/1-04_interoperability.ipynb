{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae497b71-bc43-471e-8970-88a1878e7cf9",
   "metadata": {},
   "source": [
    "# Accelerating End-to-End Data Science Workflows # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149b6d1-1880-4a5d-9d71-f963d3097aa4",
   "metadata": {},
   "source": [
    "\n",
    "## 04 - การทำงานร่วมกันของ GPU PyData Ecosystem ##\n",
    "\n",
    "**สารบัญ**\n",
    "\n",
    "โน้ตบุ๊กนี้จะนำเสนอตัวอย่างวิธีการใช้ cuDF และ CuPy ร่วมกันเพื่อใช้ประโยชน์จากฟังก์ชันการทำงานของ CuPy array (เช่น การดำเนินการพีชคณิตเชิงเส้นขั้นสูง) โน้ตบุ๊กนี้ครอบคลุมส่วนต่างๆ ดังนี้:\n",
    "\n",
    "1.  [NumPy, SciPy, และ CuPy](#NumPy,-SciPy,-and-CuPy)\n",
    "    * [cuDF vs. CuPy](#cuDF-vs.-CuPy)\n",
    "2.  [การทำงานกับ CuPy](#Working-with-CuPy)\n",
    "3.  [ตัวแปลงพิกัดกริด (Grid Converter)](#Grid-Converter)\n",
    "    * [ตัวแปลงพิกัดละติจูด/ลองจิจูดเป็น OSGB Grid ด้วย NumPy](#Lat/Long-to-OSGB-Grid-Converter-with-NumPy)\n",
    "    * [ตัวแปลงพิกัดละติจูด/ลองจิจูดเป็น OSGB Grid ด้วย CuPy](#Lat/Long-to-OSGB-Grid-Converter-with-CuPy)\n",
    "    * [แบบฝึกหัดที่ 1 - การเพิ่มคอลัมน์พิกัดกริดลงใน DataFrame](#Exercise-#1---Adding-Grid-Coordinate-Columns-to-DataFrame)\n",
    "4.  [การจัดทำดัชนีอาร์เรย์แบบบูลีน (Boolean Array Indexing)](#Boolean-Array-Indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ac5b5-5cc1-4240-9375-297cf15c6fbc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## NumPy, SciPy และ CuPy ##\n",
    "\n",
    "ตามคู่มือผู้ใช้ของตนเอง [NumPy](https://numpy.org/doc/stable/user/whatisnumpy.html) เป็นแพ็คเกจพื้นฐานสำหรับการคำนวณทางวิทยาศาสตร์ใน Python เป็นไลบรารี Python ที่มี **วัตถุอาร์เรย์หลายมิติ** วัตถุที่ได้มาต่างๆ (เช่น masked arrays และ matrices) และชุดของฟังก์ชันสำหรับการดำเนินการที่รวดเร็วบนอาร์เรย์ การดำเนินการเหล่านี้รวมถึงทางคณิตศาสตร์ ตรรกะ การจัดการรูปร่าง การเรียงลำดับ การเลือก I/O การแปลงฟูริเยร์แบบไม่ต่อเนื่อง พีชคณิตเชิงเส้นพื้นฐาน การดำเนินการทางสถิติพื้นฐาน การจำลองแบบสุ่ม และอื่นๆ อีกมากมาย ในขณะที่ NumPy มุ่งเน้นไปที่อาร์เรย์ การดำเนินการทางคณิตศาสตร์ และพีชคณิตเชิงเส้นพื้นฐาน [SciPy](https://docs.scipy.org/doc/scipy-1.8.1/tutorial/general.html) สร้างขึ้นบนรากฐานนี้เพื่อมอบฟังก์ชันการทำงานเพิ่มเติม โดยเฉพาะอย่างยิ่งในโดเมนของการคำนวณทางวิทยาศาสตร์และการปรับให้เหมาะสม\n",
    "\n",
    "ในทางกลับกัน [CuPy](https://cupy.dev/) เป็นไลบรารีอาร์เรย์โอเพนซอร์สสำหรับการคำนวณที่เร่งความเร็วด้วย GPU ด้วย Python CuPy สามารถมองได้ว่าเป็นคู่หูที่เร่งความเร็วด้วย GPU ของ NumPy โดยนำเสนอฟังก์ชันการทำงานและ API ที่คล้ายกัน พร้อมด้วยประโยชน์เพิ่มเติมของการเร่งความเร็วด้วย GPU สำหรับภาระงานที่เข้ากันได้ ในขณะที่ NumPy ทำงานบนหน่วยความจำ CPU CuPy จะทำงานกับหน่วยความจำ GPU เป็นหลัก โดยใช้ประโยชน์จาก GPU ที่เปิดใช้งาน CUDA สำหรับการคำนวณ อินเทอร์เฟซของ CuPy เข้ากันได้สูงกับ NumPy และ SciPy ในกรณีส่วนใหญ่สามารถใช้แทนกันได้ สิ่งที่เราต้องทำคือเพียงแค่แทนที่ `numpy` และ `scipy` ด้วย `cupy` และ `cupyx.scipy` ในโค้ด Python สิ่งนี้ทำให้ผู้ใช้ที่คุ้นเคยกับ NumPy สามารถเปลี่ยนไปใช้การคำนวณที่เร่งความเร็วด้วย GPU ได้ง่ายขึ้น\n",
    "\n",
    "CuPy ได้รับการออกแบบมาให้ทำงานร่วมกับไลบรารีที่เร่งความเร็วด้วย GPU อื่นๆ ในระบบนิเวศ RAPIDS ได้อย่างราบรื่น คล้ายกับที่ NumPy ทำงานกับ pandas และไลบรารีที่ใช้ CPU อื่นๆ การเก็บข้อมูลไว้บน GPU ตลอดเวิร์กโฟลว์ช่วยให้เราสามารถลดค่าใช้จ่ายในการถ่ายโอนข้อมูลระหว่างหน่วยความจำ CPU และ GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1483d0-c479-474a-a7fa-a31f4140268d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### cuDF vs. CuPy ###\n",
    "\n",
    "จนถึงตอนนี้ DataFrame ที่เราใช้งานมานั้นได้จัดเก็บข้อมูลในรูปแบบตารางที่มีโครงสร้าง ซึ่งมีประโยชน์เมื่อเราต้องการดำเนินการที่เหมือนกับ DataFrame เช่น การจัดกลุ่ม การรวมข้อมูล การกรอง และการรวมข้อมูล อย่างไรก็ตาม อาจมีกรณีการใช้งานที่จำเป็นต้องทำงานกับอาร์เรย์หลายมิติหรือเมทริกซ์ เช่น การดำเนินการทางพีชคณิตเชิงเส้นหรืองานคำนวณทางวิทยาศาสตร์ สำหรับกรณีเหล่านี้ เราจะต้องการใช้ไลบรารีที่ออกแบบมาสำหรับการทำงานเหล่านี้โดยเฉพาะ เช่น NumPy, SciPy หรือ CuPy กล่าวอีกนัยหนึ่งคือ ใช้ cuDF เมื่อทำงานกับการจัดการข้อมูลระดับสูง (นามธรรมน้อยกว่า) และใช้ CuPy เมื่อทำการดำเนินการตัวเลขระดับต่ำกับอาร์เรย์หลายมิติ\n",
    "\n",
    "ในทางปฏิบัติ นักวิทยาศาสตร์ข้อมูลส่วนใหญ่ทำงานกับทั้งสองไลบรารี เนื่องจากเวิร์กโฟลว์ส่วนใหญ่ของพวกเขาเกี่ยวข้องกับการดำเนินการ DataFrame และการคำนวณแบบอาร์เรย์ ตัวอย่างเช่น เราอาจใช้ cuDF สำหรับการโหลดและประมวลผลข้อมูล จากนั้นแปลงเป็นอาร์เรย์ CuPy สำหรับการคำนวณตัวเลขเฉพาะ และแปลงกลับเป็น cuDF เพื่อการวิเคราะห์เพิ่มเติมหรือส่งออก cuDF และ CuPy ได้รับการออกแบบมาให้ทำงานร่วมกันได้ ทำให้เราสามารถแปลงระหว่าง cuDF DataFrames/Series และอาร์เรย์ CuPy ได้อย่างง่ายดายโดยยังคงข้อมูลไว้บน GPU สิ่งนี้ช่วยให้เราสามารถสร้างเวิร์กโฟลว์ที่มีประสิทธิภาพซึ่งใช้ประโยชน์จากจุดแข็งของทั้งสองไลบรารี"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb75cf7-2590-4638-8e92-6d90a8e34b63",
   "metadata": {},
   "source": [
    "\n",
    "## การทำงานกับ CuPy ##\n",
    "\n",
    "มีหลายวิธีในการใช้งาน CuPy จาก cuDF คุณสมบัติ `DataFrame.values` จะส่งคืน CuPy representation ของ data frame นอกจากนี้ เรายังสามารถแปลงผ่าน CUDA array interface โดยใช้ `DataFrame.to_cupy()` นอกจากนี้ เรายังสามารถส่ง Series ไปยังฟังก์ชัน `cupy.asarray()` ได้ เนื่องจาก cuDF Series แสดง CUDA array interface ซึ่งเป็นแนวทางที่เร็วที่สุด\n",
    "\n",
    "ด้านล่างนี้ เราจะสาธิต **การบวกแบบแถวต่อแถว (row-wise sum)** บน DataFrame การสนับสนุนการดำเนินการแบบแถวต่อแถวของ cuDF ยังไม่สมบูรณ์นัก ดังนั้นเราจะต้องทำการ transpose DataFrame หรือเขียน UDF และคำนวณผลรวมข้ามแต่ละแถวอย่างชัดเจน การ transpose อาจทำให้มีหลายแสนคอลัมน์ (ซึ่ง cuDF จะไม่ทำงานได้ดี) ขึ้นอยู่กับรูปร่างข้อมูลของเรา และการเขียน UDF อาจใช้เวลานาน การใช้ประโยชน์จากการทำงานร่วมกันของ GPU PyData ecosystem ทำให้การดำเนินการนี้ง่ายมาก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f66072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808029f-a5e6-4066-b125-84d63c3c6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import libraries\n",
    "import cudf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50653cc1-53a1-4141-b1fb-4ef3ef7994f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "num_ele = 1000000\n",
    "\n",
    "df = cudf.DataFrame(\n",
    "    {\n",
    "        \"a\": range(num_ele),\n",
    "        \"b\": range(10, num_ele + 10),\n",
    "        \"c\": range(100, num_ele + 100),\n",
    "        \"d\": range(1000, num_ele + 1000)\n",
    "    }\n",
    ")\n",
    "\n",
    "# preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122f0a0-0354-43ed-9078-651d9761d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "start=time.time()\n",
    "display(df.sum(axis=1))\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ebab0-bff0-4b7e-aabd-c46430799983",
   "metadata": {},
   "source": [
    "การดำเนินการเดียวกันทำงานได้เร็วกว่าด้วย CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b618d3b-9b6d-423d-beb7-98334a8b3339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "arr=df.values\n",
    "\n",
    "start=time.time()\n",
    "# alternative approach\n",
    "# arr=df.to_cupy()\n",
    "\n",
    "display(arr.sum(axis=1))\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae656ac1-d4a2-499f-a904-6d1409c6ba79",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "เมื่อใช้ cuDF pandas เราสามารถใช้คุณสมบัติ `.values` รวมถึงฟังก์ชัน `cupy.asarray()` ได้ด้วย\n",
    "\n",
    "**หมายเหตุ**: เราสามารถใช้เมธอด `.to_numpy()` เพื่อแปลง cuDF DataFrames หรือ Series เป็น NumPy arrays ได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e218f5-b4ee-4d49-baff-eac5f1f76b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44200db8-d133-44c5-9f71-2796ec37df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "%load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8016e6d-829d-4117-a37c-bae82431626c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "num_ele = 1000000\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": range(num_ele),\n",
    "        \"b\": range(10, num_ele + 10),\n",
    "        \"c\": range(100, num_ele + 100),\n",
    "        \"d\": range(1000, num_ele + 1000)\n",
    "    }\n",
    ")\n",
    "\n",
    "# preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d314943-69cb-4fcd-a01a-5fe4734ff0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "arr=df.values\n",
    "# alternative approach\n",
    "# arr=cp.asarray(df)\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "display(arr.sum(axis=1))\n",
    "\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97fac8-b555-4ec1-a555-9b5ab79c2fe1",
   "metadata": {},
   "source": [
    "\n",
    "เช่นเดียวกับที่เราสามารถทำได้กับ NumPy และ pandas เราสามารถเชื่อมโยง cuDF และ CuPy เข้าด้วยกันในเวิร์กโฟลว์เดียวกัน โดยยังคงข้อมูลทั้งหมดไว้บน GPU เราสามารถย้ายไปมาระหว่างโครงสร้างข้อมูลในระบบนิเวศนี้ได้อย่างราบรื่น ทำให้เรามีความยืดหยุ่นอย่างมากโดยไม่ลดความเร็ว หากเรากำลังทำงานกับ RAPIDS cuDF แต่ต้องการฟังก์ชันที่เน้นพีชคณิตเชิงเส้นมากขึ้นซึ่งมีอยู่ใน CuPy เราสามารถใช้ประโยชน์จากการทำงานร่วมกันของ GPU PyData ecosystem เพื่อใช้ฟังก์ชันนั้นได้\n",
    "\n",
    "ในการแปลง CuPy array เป็น cuDF DataFrame หรือ Series เราสามารถใช้คอนสตรัคเตอร์ของแต่ละรายการได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea340d-c9c4-468d-8431-015492682db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "df['sum']=arr.sum(axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe3955-2849-451b-945a-c37955b91235",
   "metadata": {},
   "source": [
    "\n",
    "## ตัวแปลงพิกัดกริด (Grid Converter) ##\n",
    "\n",
    "ข้อมูลส่วนใหญ่ของเรามีพิกัดละติจูดและลองจิจูด แต่สำหรับบางงานที่เกี่ยวข้องกับระยะทาง เช่น การระบุกลุ่มผู้ติดเชื้อที่มีความหนาแน่นทางภูมิศาสตร์สูง การหาโรงพยาบาลหรือคลินิกที่ใกล้ที่สุดจากบุคคลที่กำหนด จะสะดวกกว่าถ้ามีพิกัดกริดคาร์ทีเซียนแทน โดยใช้การฉายแผนที่เฉพาะภูมิภาค (ในกรณีนี้คือ [Ordnance Survey Great Britain 1936](https://en.wikipedia.org/wiki/Ordnance_Survey_National_Grid)) เราสามารถคำนวณระยะทางในท้องถิ่นได้อย่างมีประสิทธิภาพและมีความแม่นยำที่ดี"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc82f3c-f1cb-436b-becb-a97635ec5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "dtype_dict={\n",
    "    'age': 'int8', \n",
    "    'sex': 'category', \n",
    "    'county': 'category', \n",
    "    'lat': 'float32', \n",
    "    'long': 'float32', \n",
    "    'name': 'category'\n",
    "}\n",
    "        \n",
    "df=pd.read_csv('./data/uk_pop.csv', dtype=dtype_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25cfe6a-9f31-4a13-b06f-c85a95637a44",
   "metadata": {},
   "source": [
    "### ตัวแปลงพิกัดละติจูด/ลองจิจูดเป็น OSGB Grid ด้วย NumPy ###\n",
    "\n",
    "ในการแปลงพิกัด เราจะสร้างฟังก์ชัน `latlong2osgbgrid` ซึ่งรับพิกัดละติจูด/ลองจิจูด และแปลงเป็น [พิกัด OSGB36](https://en.wikipedia.org/wiki/Ordnance_Survey_National_Grid): ค่า \"northing\" และ \"easting\" ซึ่งแสดงถึงระยะทางพิกัดคาร์ทีเซียนของจุดจากมุมตะวันตกเฉียงใต้ของกริด\n",
    "\n",
    "ด้านล่างนี้คือ `latlong2osgbgrid` ซึ่งอาศัย NumPy เป็นหลัก:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e298328-a11c-4cda-ae15-eb292fed3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ordnancesurvey.co.uk/docs/support/guide-coordinate-systems-great-britain.pdf\n",
    "\n",
    "def latlong2osgbgrid(lat, long, input_degrees=True):\n",
    "    '''\n",
    "    Converts latitude and longitude (ellipsoidal) coordinates into northing and easting (grid) coordinates, using a Transverse Mercator projection.\n",
    "    \n",
    "    Inputs:\n",
    "    lat: latitude coordinate (north)\n",
    "    long: longitude coordinate (east)\n",
    "    input_degrees: if True (default), interprets the coordinates as degrees; otherwise, interprets coordinates as radians\n",
    "    \n",
    "    Output:\n",
    "    (northing, easting)\n",
    "    '''\n",
    "    \n",
    "    if input_degrees:\n",
    "        lat = lat * np.pi/180\n",
    "        long = long * np.pi/180\n",
    "\n",
    "    a = 6377563.396\n",
    "    b = 6356256.909\n",
    "    e2 = (a**2 - b**2) / a**2\n",
    "\n",
    "    N0 = -100000                # northing of true origin\n",
    "    E0 = 400000                 # easting of true origin\n",
    "    F0 = .9996012717            # scale factor on central meridian\n",
    "    phi0 = 49 * np.pi / 180     # latitude of true origin\n",
    "    lambda0 = -2 * np.pi / 180  # longitude of true origin and central meridian\n",
    "    \n",
    "    sinlat = np.sin(lat)\n",
    "    coslat = np.cos(lat)\n",
    "    tanlat = np.tan(lat)\n",
    "    \n",
    "    latdiff = lat-phi0\n",
    "    longdiff = long-lambda0\n",
    "\n",
    "    n = (a-b) / (a+b)\n",
    "    nu = a * F0 * (1 - e2 * sinlat ** 2) ** -.5\n",
    "    rho = a * F0 * (1 - e2) * (1 - e2 * sinlat ** 2) ** -1.5\n",
    "    eta2 = nu / rho - 1\n",
    "    M = b * F0 * ((1 + n + 5/4 * (n**2 + n**3)) * latdiff - \n",
    "                  (3*(n+n**2) + 21/8 * n**3) * np.sin(latdiff) * np.cos(lat+phi0) +\n",
    "                  15/8 * (n**2 + n**3) * np.sin(2*(latdiff)) * np.cos(2*(lat+phi0)) - \n",
    "                  35/24 * n**3 * np.sin(3*(latdiff)) * np.cos(3*(lat+phi0)))\n",
    "    I = M + N0\n",
    "    II = nu/2 * sinlat * coslat\n",
    "    III = nu/24 * sinlat * coslat ** 3 * (5 - tanlat ** 2 + 9 * eta2)\n",
    "    IIIA = nu/720 * sinlat * coslat ** 5 * (61-58 * tanlat**2 + tanlat**4)\n",
    "    IV = nu * coslat\n",
    "    V = nu / 6 * coslat**3 * (nu/rho - np.tan(lat)**2)\n",
    "    VI = nu / 120 * coslat ** 5 * (5 - 18 * tanlat**2 + tanlat**4 + 14 * eta2 - 58 * tanlat**2 * eta2)\n",
    "\n",
    "    northing = I + II * longdiff**2 + III * longdiff**4 + IIIA * longdiff**6\n",
    "    easting = E0 + IV * longdiff + V * longdiff**3 + VI * longdiff**5\n",
    "\n",
    "    return(northing, easting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ddcbe5-7524-4976-a94d-ff6753da3ad8",
   "metadata": {},
   "source": [
    "### ตัวแปลง Lat/Long เป็น OSGB Grid ด้วย CuPy ###\n",
    "\n",
    "ในฟังก์ชัน `latlong2osgbgrid_cupy` ที่จะตามมา เราเพียงแค่สลับ `cp` แทน `np` ในขณะที่ CuPy รองรับงานที่เร่งความเร็วด้วย GPU ที่ทรงพลังหลากหลายประเภท เทคนิคที่เรียบง่ายนี้ในการสามารถสลับการเรียกใช้ CuPy แทนการเรียกใช้ NumPy ทำให้เป็นเครื่องมือที่มีประสิทธิภาพอย่างไม่น่าเชื่อที่เรามีพร้อมใช้งาน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffa2a3-34ba-4664-9399-4b74cc28f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ordnancesurvey.co.uk/docs/support/guide-coordinate-systems-great-britain.pdf\n",
    "\n",
    "def latlong2osgbgrid_cupy(lat, long, input_degrees=True):\n",
    "    '''\n",
    "    Converts latitude and longitude (ellipsoidal) coordinates into northing and easting (grid) coordinates, using a Transverse Mercator projection.\n",
    "    \n",
    "    Inputs:\n",
    "    lat: latitude coordinate (north)\n",
    "    long: longitude coordinate (east)\n",
    "    input_degrees: if True (default), interprets the coordinates as degrees; otherwise, interprets coordinates as radians\n",
    "    \n",
    "    Output:\n",
    "    (northing, easting)\n",
    "    '''\n",
    "    \n",
    "    if input_degrees:\n",
    "        lat = lat * cp.pi/180\n",
    "        long = long * cp.pi/180\n",
    "\n",
    "    a = 6377563.396\n",
    "    b = 6356256.909\n",
    "    e2 = (a**2 - b**2) / a**2\n",
    "\n",
    "    N0 = -100000                 # northing of true origin\n",
    "    E0 = 400000                  # easting of true origin\n",
    "    F0 = .9996012717             # scale factor on central meridian\n",
    "    phi0 = 49 * cp.pi / 180      # latitude of true origin\n",
    "    lambda0 = -2 * cp.pi / 180   # longitude of true origin and central meridian\n",
    "    \n",
    "    sinlat = cp.sin(lat)\n",
    "    coslat = cp.cos(lat)\n",
    "    tanlat = cp.tan(lat)\n",
    "    \n",
    "    latdiff = lat-phi0\n",
    "    longdiff = long-lambda0\n",
    "\n",
    "    n = (a-b) / (a+b)\n",
    "    nu = a * F0 * (1 - e2 * sinlat ** 2) ** -.5\n",
    "    rho = a * F0 * (1 - e2) * (1 - e2 * sinlat ** 2) ** -1.5\n",
    "    eta2 = nu / rho - 1\n",
    "    M = b * F0 * ((1 + n + 5/4 * (n**2 + n**3)) * latdiff - \n",
    "                  (3*(n+n**2) + 21/8 * n**3) * cp.sin(latdiff) * cp.cos(lat+phi0) +\n",
    "                  15/8 * (n**2 + n**3) * cp.sin(2*(latdiff)) * cp.cos(2*(lat+phi0)) - \n",
    "                  35/24 * n**3 * cp.sin(3*(latdiff)) * cp.cos(3*(lat+phi0)))\n",
    "    I = M + N0\n",
    "    II = nu/2 * sinlat * coslat\n",
    "    III = nu/24 * sinlat * coslat ** 3 * (5 - tanlat ** 2 + 9 * eta2)\n",
    "    IIIA = nu/720 * sinlat * coslat ** 5 * (61-58 * tanlat**2 + tanlat**4)\n",
    "    IV = nu * coslat\n",
    "    V = nu / 6 * coslat**3 * (nu/rho - cp.tan(lat)**2)\n",
    "    VI = nu / 120 * coslat ** 5 * (5 - 18 * tanlat**2 + tanlat**4 + 14 * eta2 - 58 * tanlat**2 * eta2)\n",
    "\n",
    "    northing = I + II * longdiff**2 + III * longdiff**4 + IIIA * longdiff**6\n",
    "    easting = E0 + IV * longdiff + V * longdiff**3 + VI * longdiff**5\n",
    "\n",
    "    return(northing, easting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f1ea5-595d-4933-afb0-29fa75feea29",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ด้านล่างนี้ เราจะส่งพิกัดละติจูด/ลองจิจูดไปยังตัวแปลง ซึ่งจะส่งค่าเหนือและตะวันออกภายใน OSGB grid กลับมาให้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f24b6-0a70-4ad0-897b-fdbb9dee3cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# DO NOT CHANGE THIS CELL\n",
    "numpy_lat = np.asarray(df['lat'])\n",
    "numpy_long = np.asarray(df['long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2feb1-29a8-420c-80ab-62fff620edaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# DO NOT CHANGE THIS CELL\n",
    "n_numpy_array, e_numpy_array = latlong2osgbgrid(numpy_lat, numpy_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f10d6f-2044-4517-904e-c9bd46350f17",
   "metadata": {},
   "source": [
    "### แบบฝึกหัดที่ 1 - การเพิ่มคอลัมน์พิกัดกริดลงใน DataFrame ###\n",
    "\n",
    "ตอนนี้เราจะใช้ `latlong2osgbgrid_cupy` เพื่อเพิ่มคอลัมน์ `northing` และ `easting` ลงใน `df` เราจะเริ่มต้นด้วยการแปลงสองคอลัมน์ที่เราต้องการ คือ `lat` และ `long` ให้เป็น CuPy arrays ด้วยฟังก์ชัน `cp.asarray()` เนื่องจาก cuDF และ CuPy เชื่อมต่อกันโดยตรงผ่าน `__cuda_array_interface__` การแปลงจึงเกิดขึ้นได้ในหน่วยนาโนวินาที\n",
    "\n",
    "**คำแนะนำ**:\n",
    "* รันเซลล์ด้านล่างเพื่อสร้าง CuPy arrays สำหรับคอลัมน์ `lat` และ `long`\n",
    "* แก้ไขเฉพาะส่วน `<FIXME>` และรันเซลล์ด้านล่างเพื่อใช้ `latlong2osgbgrid_cupy` กับ `cupy_lat` และ `cupy_long` จากนั้นเพิ่มเป็นคอลัมน์ `northing` และ `easting` โดยมี dtype เป็น `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3febd9fb-fc44-41f6-9712-60902da18d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# DO NOT CHANGE THIS CELL\n",
    "cupy_lat = cp.asarray(df['lat'])\n",
    "cupy_long = cp.asarray(df['long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7cadb-402e-44a7-9994-4635707b8cd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_cupy_array, e_cupy_array = <<<<FIXME>>>>\n",
    "df['northing'] = <<<<FIXME>>>>\n",
    "df['easting'] = <<<<FIXME>>>>\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b2b3c0b-df22-4a53-9628-a71d226d3efd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "\n",
    "%%time\n",
    "n_cupy_array, e_cupy_array = latlong2osgbgrid_cupy(cupy_lat, cupy_long)\n",
    "df['northing'] = pd.Series(n_cupy_array).astype('float32')\n",
    "df['easting'] = e_cupy_array.astype('float32')\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82640e5c-ae3a-495b-bc48-df9b46f5d4b1",
   "metadata": {},
   "source": [
    "Click ... for solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e92cb7-c138-49ae-9aa4-e55f76235b98",
   "metadata": {},
   "source": [
    "## การจัดทำดัชนีอาร์เรย์แบบบูลีน (Boolean Array Indexing) ##\n",
    "\n",
    "ด้านล่างนี้ เราจะใช้ `np.logical_and` สำหรับการเลือกค่าบูลีนแบบทีละองค์ประกอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7946d-f239-4c5b-9c38-2057aa88a085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "start=time.time()\n",
    "display(df.loc[np.logical_and(df['name'].str.startswith('E'), df['name'].str.endswith('D'))].head())\n",
    "print(f'Duration: {round(time.time()-start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f768cdc-3412-4256-921e-ffccfdcd6058",
   "metadata": {},
   "source": [
    "ด้านล่างนี้ เราจะใช้ CuPy สำหรับการเลือกแบบบูลีน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac5517-c69b-4355-81e0-1e94deddcb2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "start=time.time()\n",
    "display(df.loc[cp.logical_and(df['name'].str.startswith('E'), df['name'].str.endswith('D'))].head())\n",
    "print(f'Duration: {round(time.time()-start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cab4f4-eff4-4b09-a68d-dc1c089bfa72",
   "metadata": {},
   "source": [
    "**หมายเหตุ**: อาร์เรย์สตริงยังไม่ได้ถูกนำมาใช้ใน CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321b4f6-61c6-4968-a77b-3d3ed4cde745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d91047-2067-42f7-89b5-e9915eefb1de",
   "metadata": {},
   "source": [
    "**เยี่ยมมาก!** ไปยัง [โน้ตบุ๊กถัดไป](1-05_grouping.ipynb) กันเลย"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb4ab1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
