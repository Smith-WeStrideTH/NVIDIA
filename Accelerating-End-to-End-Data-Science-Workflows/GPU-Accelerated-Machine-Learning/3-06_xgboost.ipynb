{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerating End-to-End Data Science Workflows # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - XGBoost ##\n",
    "\n",
    "**สารบัญ**\n",
    "<br>\n",
    "สมุดบันทึก (notebook) นี้จะใช้การบูสติ้งแบบไล่ระดับความชันที่เร่งความเร็วด้วย GPU เพื่อทำนายความน่าจะเป็นที่บุคคลหนึ่งติดเชื้อไวรัสจำลอง สมุดบันทึกนี้ครอบคลุมหัวข้อด้านล่าง:\n",
    "1. [สภาพแวดล้อม(Environment)](#Environment)\n",
    "2. [โหลดข้อมูล(Load-Data)](#Load-Data)\n",
    "3. [แบ่งข้อมูลสำหรับฝึกและทดสอบ (Train-Test-Split)](#Train-Test-Split)\n",
    "4. [XGBoost](#XGBoost)\n",
    "    * [การตั้งค่าพารามิเตอร์ XGBoost](#Setting-XGBoost-Parameters)\n",
    "    * [การฝึกโมเดล](#Training-the-Model)\n",
    "5. [การตรวจสอบโมเดล](#Inspecting-the-Model)\n",
    "6. [การทำนายผล](#Making-Predictions)\n",
    "7. [(ทางเลือก) การเปรียบเทียบ: XGBoost เฉพาะ CPU](#(Optional)-Comparison:-CPU-Only-XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สภาพเเวดล้อม ##\n",
    "เราจะใช้ไลบรารี [XGBoost](https://xgboost.readthedocs.io/en/latest/) เพื่อสร้างโมเดล Gradient Boosted สำหรับแบบฝึกหัดนี้\n",
    "\n",
    "นอกเหนือจากส่วนประกอบปกติของ RAPIDS แล้ว เรายังอิมพอร์ตไลบรารีหลายตัวที่จะช่วยให้เราเข้าใจและประเมินโมเดล XGBoost หลังจากที่เราได้ฝึกฝนมันแล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuml\n",
    "import cupy as cp\n",
    "\n",
    "from cuml.model_selection import train_test_split\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "\n",
    "# model analysis\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# xgboost version 1.0 or later is required to directly convert from cudf Dataframes to xgboost DMatrix format\n",
    "print('XGBoost version: ', xgb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## โหลดข้อมูล ##\n",
    "สำหรับหน้านี้ (notebook) เราจะโหลดข้อมูลประชากรมาเพียงบางส่วน ซึ่งรวมถึงทั้งคอลัมน์ที่เราเคยใช้สำหรับการถดถอยโลจิสติกส์ (logistic regression) และคอลัมน์พิกัดด้วย XGBoost ช่วยให้เราสามารถใช้ข้อมูลที่มีความสัมพันธ์แบบไม่เชิงเส้น (nonlinear relationships) กับผลลัพธ์ที่เราสนใจได้ และข้อมูลเชิงพื้นที่ (geospatial data) มักจะจัดอยู่ในประเภทนั้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.read_csv('./data/clean_uk_pop_full.csv', usecols=['age', 'sex', 'northing', 'easting', 'infected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ก่อนที่เราจะแบ่งข้อมูลสำหรับฝึกฝน (training) และทดสอบ (testing) เราจะตรวจสอบสถานะหน่วยความจำของเราครับ เราต้องการให้การใช้งานหน่วยความจำอยู่ต่ำกว่าครึ่งหนึ่งของหน่วยความจำทั้งหมดบน GPU ที่กำลังใช้งาน เพื่อให้การเพิ่มขึ้นชั่วคราวจากการแบ่งข้อมูลยังคงสามารถจัดเก็บในหน่วยความจำได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การแบ่งข้อมูล (Train-Test Split) ##\n",
    "เราจะใช้วิธีการแบ่งข้อมูล (splitting method) อีกครั้งเพื่อสร้างชุดข้อมูลย่อยสำหรับ **การฝึก (training)** และ **การทดสอบ (testing)** โดยคำนึงว่าการทำเช่นนี้จะใช้หน่วยความจำเพิ่มขึ้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(gdf[['age', 'sex', 'northing', 'easting']], gdf['infected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ข้อสังเกต**: ตอนนี้เรามีชุดข้อมูลสำหรับ **ฝึก (training)** และ **ทดสอบ (testing)** แล้ว เราสามารถลบข้อมูลต้นฉบับออกได้ เพื่อเพิ่มพื้นที่ว่างสำหรับหน่วยความจำเสริมของอัลกอริทึม ซึ่งในกรณีนี้อาจจะไม่สำคัญนัก แต่ก็เป็นวิธีปฏิบัติที่เป็นประโยชน์เมื่อพยายามฝึกโมเดลด้วยข้อมูลให้ได้มากที่สุดเท่าที่จะทำได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การตั้งค่าพารามิเตอร์ XGBoost ###\n",
    "ตอนนี้เราสามารถตั้งค่าพารามิเตอร์สำหรับการรันเทรน XGBoost นี้ได้แล้ว โดยพารามิเตอร์เหล่านี้จะกำหนดประเภทและขนาดของต้นไม้ที่จะถูกสร้างขึ้น รวมถึงวิธีการที่เราใช้วัดผลความสำเร็จ\n",
    "\n",
    "พารามิเตอร์ที่สำคัญคือ `cuda`: ซึ่งเป็นการบอก XGBoost ว่าเราต้องการให้การเทรนทำงานบน **GPU**\n",
    "\n",
    "สำหรับกรณีการใช้งานของเรา เราต้องการทำนายความน่าจะเป็นที่บุคคลจะติดเชื้อไวรัสอีกครั้ง ดังนั้นเราจึงตั้งค่า **objective** เป็น `binary:logistic` (ผลลัพธ์แบบไบนารี โดยใช้วิธีโลจิสติกเพื่อหาความน่าจะเป็น)\n",
    "\n",
    "ตัวเลือกพารามิเตอร์และความหมายอื่นๆ สามารถดูได้ที่ [พารามิเตอร์ XGBoost](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':    8,\n",
    "    'max_leaves':   2**8,\n",
    "    'device': 'cuda',\n",
    "    'tree_method':  'hist',\n",
    "    'objective':    'binary:logistic',\n",
    "    'grow_policy':  'lossguide',\n",
    "    'eval_metric':  'logloss',\n",
    "    'subsample':    '0.8'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การฝึกโมเดล (Training the Model) ###\n",
    "XGBoost ใช้โครงสร้างข้อมูลพิเศษที่มีประสิทธิภาพสูงที่เรียกว่า `DMatrix` ดังนั้นเราจึงส่ง DataFrame สำหรับการฝึก (training dataframes) เข้าไปเพื่อสร้าง `DMatrix`\n",
    "\n",
    "โปรดทราบว่าข้อมูลยังคงอยู่บน GPU โดยจะส่งผ่านจาก cuDF ไปยัง XGBoost โดยตรง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทีนี้ เราก็พร้อมที่จะ **ฝึกโมเดล (train the model)** แล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgboost_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ข้อสังเกต**: เพื่อใช้เป็นจุดเปรียบเทียบ โค้ดสำหรับรัน XGBoost เวอร์ชันที่ใช้ CPU เท่านั้น จะมีให้ที่ส่วนท้ายของแบบฝึกหัดนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ตรวจสอบโมเดล ##\n",
    "เราสามารถตรวจสอบโมเดลได้หลายวิธี ก่อนอื่น เราสามารถดูว่าฟีเจอร์ใดที่โมเดลเชื่อว่าสำคัญที่สุดในการประเมิน คะแนน F ที่สูงขึ้นบ่งชี้ถึงความสำคัญที่ประเมินไว้สูงขึ้น\n",
    "\n",
    "ดูเหมือนว่ามีองค์ประกอบทาง **ภูมิสารสนเทศ (geospatial)** ที่แข็งแกร่งต่อการกระจายของการติดเชื้อ เนื่องจากฟีเจอร์ **easting** และ **northing** มีคะแนน F สูงที่สุด นอกจากนี้ **อายุ (age)** ดูเหมือนจะมีผลกระทบมากกว่า **เพศ (sex)** ในการกำหนดอัตราการติดเชื้อ (ซึ่งสอดคล้องกับผลลัพธ์ที่เราได้รับจากการวิเคราะห์ Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(model, height=.8)\n",
    "ax.grid(False)\n",
    "ax.set_title('F score by feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เรายังสามารถดึง **แต่ละต้นไม้ (individual trees)** ออกมาจากโมเดล และดูว่ามันใช้การตัดสินใจอะไรบ้างในการสนับสนุนผลลัพธ์โดยรวม (ensemble) โปรดสังเกตว่า เช่นเดียวกับวิธีการแบบ **ensemble** อื่นๆ ต้นไม้แต่ละต้นอาจดูเหมือนไม่ได้สร้างความแตกต่างอย่างมีนัยสำคัญในผลลัพธ์ (ค่าบนโหนดใบไม้) แต่การรวมกันของต้นไม้ที่แต่ละต้นอาจอ่อนแอหลายๆ ต้นเข้าด้วยกันให้เป็นโมเดลที่แข็งแกร่ง คือสิ่งที่ทำให้ XGBoost มีประสิทธิภาพ\n",
    "\n",
    "ลองเปลี่ยนค่า `num_trees` เพื่อตรวจสอบต้นไม้ที่แตกต่างกันในโมเดล การเปลี่ยน `rankdir` เป็น `'TB'` จะปรับทิศทางของต้นไม้ให้เป็นแบบบนลงล่าง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(model, num_trees=0, rankdir='LR')\n",
    "\n",
    "# get current figure to set the size\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การคาดการณ์ (Making Predictions) ##\n",
    "เมื่อเราคุ้นเคยกับโมเดลแล้ว เราก็จะเริ่มทำการคาดการณ์ด้วยโมเดลนั้น เรายืนยันว่าจะทำการคาดการณ์บนข้อมูลมากกว่า 11 ล้านแถว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราจะแปลงเมทริกซ์ *X* ให้เป็น `DMatrix` เหมือนเดิม จากนั้นทำการคาดการณ์ (prediction) สำหรับแต่ละแถว **สังเกตเวลาที่ใช้ในการคาดการณ์กว่า 11 ล้านรายการ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(x_test)\n",
    "%time y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตอนนี้เราต้องการดูว่าการทำนายเหล่านั้นดีแค่ไหน วิธีการประเมินทั่วไปคือการคำนวณ **พื้นที่ใต้กราฟ (AUC)** ของ **กราฟคุณลักษณะการทำงานของตัวรับ (ROC curve)**\n",
    "\n",
    "การทำนายเป็นอาร์เรย์ `numpy` ดังนั้นเราจึงแปลงป้ายกำกับการทดสอบให้ตรงกัน จากนั้นจึงทำการคำนวณ ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cpu = cp.asnumpy(cp.array(y_test))\n",
    "false_pos_rate, true_pos_rate, thresholds = roc_curve(y_test_cpu, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุดท้าย เราสามารถพล็อต เส้นโค้ง (curve) และคำนวณ คะแนน AUC (AUC score) เพื่อช่วยให้เราประเมินความสัมพันธ์ระหว่างอัตราการเกิดผลบวกจริง (true positive rates) และอัตราการเกิดผลบวกปลอม (false positive rates) ได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_result = auc(false_pos_rate, true_pos_rate)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(false_pos_rate, true_pos_rate, lw=3,\n",
    "        label='AUC = {:.2f}'.format(auc_result))\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "ax.set(\n",
    "    xlim=(0, 1),\n",
    "    ylim=(0, 1),\n",
    "    title=\"ROC Curve\",\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    ")\n",
    "ax.legend(loc='lower right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ทางเลือก) การเปรียบเทียบ: XGBoost เฉพาะ CPU ##\n",
    "ด้านล่างนี้ เราได้เตรียมโค้ดสำหรับการฝึก (training) และการอนุมาน (inferring) โดยใช้ XGBoost เฉพาะ CPU ซึ่งใช้พารามิเตอร์โมเดลเดียวกัน เพียงแต่เปลี่ยนวิธีการสร้างฮิสโตแกรมของทรี (histogram tree method) จาก GPU เป็น CPU เท่านั้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['device'] = 'cpu'\n",
    "dtrain_cpu = xgb.DMatrix(x_train.to_pandas(), y_train.to_pandas())\n",
    "%time model_cpu = xgb.train(params, dtrain_cpu, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest_cpu = xgb.DMatrix(x_test.to_pandas())\n",
    "%time y_pred_cpu = model_cpu.predict(dtest_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**เยี่ยมมาก!** ไปยัง [สมุดบันทึกถัดไป](3-07_triton.ipynb) กันเลย"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
